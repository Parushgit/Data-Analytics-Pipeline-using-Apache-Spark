{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------Lab3---------------------------------------------\n",
    "#Using NYTimes API to fetch the results for articles\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element.encode('utf-8'))):\n",
    "        return False\n",
    "    return True\n",
    " \n",
    "\n",
    "api_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=e01288d6543146f594717ec949cdb61b&q=Technology\"\n",
    "# api_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=e01288d6543146f594717ec949cdb61b&q=Sports\"\n",
    "# api_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=e01288d6543146f594717ec949cdb61b&q=Business\"\n",
    "# api_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=e01288d6543146f594717ec949cdb61b&q=Politics\"\n",
    "\n",
    "page = 100\n",
    "count = 0\n",
    "\n",
    "# For unknown data set\n",
    "file_name = 'FileTechnologyUnknown'; \n",
    "# file_name = 'FileSportsUnknown'; \n",
    "# file_name = 'FileBusinessUnknown'; \n",
    "# file_name = 'FilePoliticsUnknown'; \n",
    "\n",
    "# For total data set\n",
    "# file_name = 'FileTechnologyRaw'; \n",
    "# file_name = 'FileSportsRaw'; \n",
    "# file_name = 'FileBusinessRaw'; \n",
    "# file_name = 'FilePoliticsRaw'; \n",
    "\n",
    "j = 1;\n",
    "while (1):\n",
    "    api_url = api_url + \"&page=\" + str(count)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        data_url = urlopen(api_url)\n",
    "        response_url = data_url.read()\n",
    "        json_url_data = json.loads(response_url)\n",
    "    except:\n",
    "        pass\n",
    "    for i in json_url_data['response']['docs']:\n",
    "        weburl = i['web_url']\n",
    "        weburl_str = str(weburl)\n",
    "        if weburl_str.find(\"topics.nytimes.com\") == -1:\n",
    "            file_name_cpy = file_name + str(j) + '.txt'\n",
    "            file = open(file_name_cpy,'wb')\n",
    "            try:\n",
    "                html = urllib.request.urlopen(weburl)\n",
    "                j = j + 1\n",
    "            except:\n",
    "                pass\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            ptags = soup.find_all(\"p\",text=True)   \n",
    "            for par in ptags:\n",
    "                file.write((par.get_text(strip=True)).encode('utf8'))\n",
    "            file.close()\n",
    "    if j > 51:\n",
    "        break\n",
    "    api_url = api_url.partition(\"&page=\")[0]\n",
    "    count = count + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
